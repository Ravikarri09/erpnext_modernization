ğŸš€ ERPNext Code Intelligence RAG System

An AI-powered code intelligence platform that understands the ERPNext codebase and answers developer questions using Retrieval-Augmented Generation (RAG).

This system converts ERPNextâ€™s source code into a searchable knowledge base using static analysis, embeddings, and a vector database â€” enabling an AI assistant to answer questions directly from the code.

ğŸ” Problem Statement

ERPNext is a large Python-based ERP system with thousands of files and complex business logic.
Understanding workflows like tax calculation, invoice validation, stock updates, and submission logic takes significant time for developers.

This project solves that by building a code-aware AI assistant that:

Understands ERPNextâ€™s internal structure

Searches relevant code automatically

Answers questions with real source-code context

ğŸ— System Architecture
ERPNext Source Code
        â†“
Static Code Analyzer (AST)
        â†“
Extracted Functions & Classes (JSON)
        â†“
Code Chunking
        â†“
Embeddings (Ollama)
        â†“
FAISS Vector Database
        â†“
RAG Pipeline
        â†“
AI Assistant

âš™ï¸ Features

ğŸ” Static code analysis using Python AST

ğŸ“¦ Automatic extraction of:

Functions

Classes

Call relationships

ğŸ§  Semantic embeddings using Ollama

âš¡ FAISS vector database for fast search

ğŸ¤– RAG-based AI assistant

ğŸ’¬ Natural language querying of ERPNext code

ğŸ“ Project Structure
mini_erp_analyzer/
â”‚
â”œâ”€â”€ Analyzer/              # Static code analyzer
â”‚   â””â”€â”€ analyzer.py
â”‚
â”œâ”€â”€ data/                 # Extracted and processed data
â”‚   â”œâ”€â”€ functions.json
â”‚   â”œâ”€â”€ classes.json
â”‚   â”œâ”€â”€ calls.json
â”‚   â””â”€â”€ code_chunks.json
â”‚
â”œâ”€â”€ rag/                  # RAG pipeline
â”‚   â”œâ”€â”€ chunker.py
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â””â”€â”€ rag_query.py
â”‚
â”œâ”€â”€ llm/                  # LLM & embedding layer
â”‚   â”œâ”€â”€ ollama_embed.py
â”‚   â”œâ”€â”€ ollama_llm.py
â”‚   â””â”€â”€ safe_generate.py
â”‚
â”œâ”€â”€ vector_db/            # FAISS index
â”‚   â””â”€â”€ faiss.index
â”‚
â”œâ”€â”€ config.py
â”œâ”€â”€ app.py               # Main AI assistant app
â””â”€â”€ README.md

ğŸ”§ Tech Stack

Python

AST (Static Code Parsing)

Ollama (Local Embeddings + LLM)

FAISS (Vector Database)

RAG (Retrieval-Augmented Generation)

ğŸš€ How It Works
1. Static Code Analysis

ERPNext source code is parsed using Pythonâ€™s AST module to extract:

Functions

Classes

Call relationships

2. Chunking

Each function is converted into a semantic chunk:

Function validate in erpnext/accounts/sales_invoice.py at line 82

3. Embeddings

Chunks are embedded using Ollamaâ€™s nomic-embed-text model.

4. Vector Database

All embeddings are stored in a FAISS index for fast similarity search.

5. RAG Pipeline

When a question is asked:

Relevant chunks are retrieved from FAISS

Context is injected into the LLM prompt

AI generates an answer grounded in real code

â–¶ Running the Project
Step 1 â€” Start Ollama
ollama serve


Pull required models:

ollama pull nomic-embed-text
ollama pull llama3.2

Step 2 â€” Run Code Analyzer
python Analyzer/analyzer.py

Step 3 â€” Create Code Chunks
python -m rag.chunker

Step 4 â€” Build Vector Database (Fast Mode)
python -m rag.vector_store

Step 5 â€” Run AI Assistant
python app.py


Ask:

Where is tax calculated in ERPNext?
